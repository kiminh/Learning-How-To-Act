{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinUCB():\n",
    "    '''\n",
    "        This class implements LinUCB Disjoint algorithm\n",
    "    '''\n",
    "    \n",
    "    def __init__( self,  arm_ids, alpha, ctxtVecLen):\n",
    "        \n",
    "        '''\n",
    "            alpha : Controls exploration; \n",
    "                    Higher the alpha, wider the confidence interval and higher the chance of trying any given arm;\n",
    "           \n",
    "            kArms: Number of arms\n",
    "            \n",
    "            ctxtVecLen: length of the feature vector\n",
    "            \n",
    "        '''\n",
    "        \n",
    "        self.kArms      = len(arm_ids)\n",
    "        self.alpha      = alpha\n",
    "        self.ctxtVecLen = ctxtVecLen\n",
    "        \n",
    "        # A: (ctxtVecLen x ctxtVecLen) matrix = D_a.T * D_a + I_d  ( Where a is indexing on arms array)\n",
    "        # The inverse of A is used in ridge regression \n",
    "        self.A_a = {}\n",
    "        for idx, arm_id in enumerate(arm_ids):\n",
    "            self.A_a[arm_id] = np.identity(ctxtVecLen) # A = D_T * D ( Where D is n*p matrix)\n",
    "\n",
    "        # b: (ctxtVecLen x 1) corresponding response vector. \n",
    "        # Equals to D_a.T * c_a in ridge regression formulation\n",
    "        self.b_a = {}\n",
    "        for idx, arm_id in enumerate(arm_ids):\n",
    "            self.b_a[arm_id] = np.zeros([ctxtVecLen,1]) # b = D_T * RV ( where RV is n*1 matrix )\n",
    "        \n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f'LinUCB Object with {kArms} arms and with alpha {alpha}'.format(self.alpha, self.kArms, self.ctxtVecLen) \n",
    "    \n",
    "    def select_arm(self, ctxtVec):\n",
    "        ''' Returns the index of the next arm to pull '''    \n",
    "        \n",
    "        # Reshape covariates input into (d x 1) shape vector\n",
    "        ctxtVec = ctxtVec.reshape([-1,1])\n",
    "\n",
    "        ucb = []\n",
    "        for idx, arm_id in enumerate(np.random.permutation(list(LinUCBPolicy.A_a.keys()) )):\n",
    "            # Find A inverse for ridge regression\n",
    "            A_inv = np.linalg.inv(self.A_a[arm_id])\n",
    "            \n",
    "            # Perform ridge regression to obtain estimate of covariate coefficients theta\n",
    "            # theta is (ctxtVecLen x 1) dimension vector\n",
    "            theta = np.dot(A_inv, self.b_a[arm_id])\n",
    "            \n",
    "            ucb.append( \n",
    "                (\n",
    "                    arm_id,\n",
    "                    (np.dot(theta.T, ctxtVec) + self.alpha * np.sqrt(np.dot(ctxtVec.T, np.dot(A_inv,ctxtVec))))[0][0] \n",
    "                )\n",
    "            )                \n",
    "        return( max(ucb,key=lambda x:x[1])[0] )            \n",
    "    \n",
    "    def update(self, ctxtVec, chosen_arm, reward):\n",
    "        '''        \n",
    "            After we pull an arm, we get a reward signal back from our system. This function update our algorithm's beliefs\n",
    "            about the quality of the arm we just chosen by providing this reward information.\n",
    "        \n",
    "            chosen_arm : The numeric index of the most recently chosen arm\n",
    "            reward     : The reward received from chossing that arm\n",
    "        '''\n",
    "        \n",
    "        # Reshape covariates input into (d x 1) shape vector\n",
    "        ctxtVec = ctxtVec.reshape([-1,1])        \n",
    "    \n",
    "        # Update A which is (d * d) matrix.\n",
    "        self.A_a[chosen_arm] += np.dot(ctxtVec, ctxtVec.T)\n",
    "        \n",
    "        # Update b which is (d x 1) vector\n",
    "        # reward is scalar\n",
    "        self.b_a[chosen_arm] += reward * ctxtVec                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinUCB Object with 10 arms and with alpha 0\n",
      "Total Estimated Reward:\t 0.8386783284742468\n",
      "armSelCntr:  Counter({2: 299, 7: 223, 3: 152, 9: 143, 6: 68, 4: 42, 10: 34, 5: 30, 8: 27, 1: 11})\n",
      "armRewCntr:  Counter({2: 258.0, 7: 201.0, 9: 126.0, 3: 126.0, 6: 59.0, 4: 33.0, 10: 21.0, 8: 21.0, 5: 18.0, 1: 0.0})\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "LinUCB Object with 10 arms and with alpha 0.25\n",
      "Total Estimated Reward:\t 0.41358641358641357\n",
      "armSelCntr:  Counter({2: 167, 7: 132, 9: 107, 3: 103, 6: 87, 5: 84, 4: 82, 8: 81, 1: 80, 10: 78})\n",
      "armRewCntr:  Counter({2: 126.0, 7: 90.0, 9: 60.0, 3: 56.0, 6: 29.0, 5: 17.0, 4: 15.0, 8: 9.0, 1: 8.0, 10: 4.0})\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "LinUCB Object with 10 arms and with alpha 0.5\n",
      "Total Estimated Reward:\t 0.27623762376237626\n",
      "armSelCntr:  Counter({2: 151, 7: 109, 9: 101, 3: 99, 6: 93, 4: 92, 5: 92, 1: 92, 8: 91, 10: 90})\n",
      "armRewCntr:  Counter({2: 97.0, 7: 48.0, 9: 38.0, 3: 35.0, 6: 21.0, 5: 14.0, 4: 10.0, 8: 7.0, 1: 5.0, 10: 4.0})\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "LinUCB Object with 10 arms and with alpha 0.75\n",
      "Total Estimated Reward:\t 0.20330237358101136\n",
      "armSelCntr:  Counter({2: 125, 7: 100, 9: 97, 3: 96, 6: 94, 10: 93, 8: 92, 4: 92, 5: 91, 1: 89})\n",
      "armRewCntr:  Counter({2: 68.0, 7: 37.0, 9: 27.0, 3: 23.0, 6: 16.0, 4: 9.0, 5: 6.0, 8: 5.0, 10: 5.0, 1: 1.0})\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "LinUCB Object with 10 arms and with alpha 1.0\n",
      "Total Estimated Reward:\t 0.18895348837209303\n",
      "armSelCntr:  Counter({2: 132, 7: 104, 3: 102, 4: 101, 9: 100, 5: 100, 1: 99, 10: 99, 8: 98, 6: 97})\n",
      "armRewCntr:  Counter({2: 70.0, 7: 35.0, 9: 26.0, 3: 21.0, 6: 17.0, 4: 10.0, 5: 8.0, 8: 4.0, 1: 2.0, 10: 2.0})\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "LinUCB Object with 10 arms and with alpha 1.25\n",
      "Total Estimated Reward:\t 0.1696512723845429\n",
      "armSelCntr:  Counter({2: 130, 7: 111, 3: 107, 9: 106, 4: 102, 6: 102, 1: 102, 5: 101, 10: 100, 8: 100})\n",
      "armRewCntr:  Counter({2: 62.0, 7: 33.0, 9: 22.0, 3: 22.0, 6: 15.0, 5: 8.0, 4: 6.0, 10: 4.0, 1: 4.0, 8: 4.0})\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "LinUCB Object with 10 arms and with alpha 1.5\n",
      "Total Estimated Reward:\t 0.15854823304680038\n",
      "armSelCntr:  Counter({2: 123, 7: 107, 9: 104, 4: 104, 5: 102, 3: 102, 10: 102, 8: 101, 1: 101, 6: 101})\n",
      "armRewCntr:  Counter({2: 55.0, 7: 30.0, 9: 27.0, 3: 20.0, 6: 10.0, 4: 8.0, 5: 7.0, 10: 4.0, 8: 3.0, 1: 2.0})\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "estimated_rewards_alphas = {}\n",
    "for alpha in [0, 0.25, 0.5, 0.75, 1.0, 1.25, 1.5]:\n",
    "#     alpha      = 0.25  # scalar factor on confidence interval ( higher the value higher the exploration )\n",
    "    ctxtVecLen = 100\n",
    "    arms_ids = list( range(1, kArms+1))\n",
    "    LinUCBPolicy = LinUCB(arms_ids, alpha, ctxtVecLen)        \n",
    "    print(LinUCBPolicy)\n",
    "\n",
    "    armSelCntr = Counter()\n",
    "    armRewCntr = Counter()\n",
    "\n",
    "    with open('./dataset.txt') as fp:\n",
    "        for idx, eachRecord in enumerate(fp):\n",
    "            data_arm = int(eachRecord.split(' ')[0])\n",
    "            data_reward = float(eachRecord.split()[1])\n",
    "            covariate_string_list = eachRecord.split()[2:]        \n",
    "            data_x_array = np.array([float(eCov) for eCov in eachRecord.split()[2:]])\n",
    "            selected_arm = LinUCBPolicy.select_arm( data_x_array )\n",
    "\n",
    "            if selected_arm == data_arm:\n",
    "                armSelCntr[selected_arm] += 1\n",
    "                LinUCBPolicy.update(data_x_array, selected_arm, data_reward) \n",
    "                armRewCntr[selected_arm] += data_reward\n",
    "\n",
    "    print('Total Estimated Reward:\\t', sum(armRewCntr.values())/sum(armSelCntr.values()) )\n",
    "    print('armSelCntr: ', armSelCntr)\n",
    "    print('armRewCntr: ', armRewCntr)\n",
    "    print('\\n\\n\\n')\n",
    "    \n",
    "    estimated_rewards_alphas[alpha] = sum(armRewCntr.values())/sum(armSelCntr.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
