{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "kArms      = 10\n",
    "alpha      = 1.5  # scalar factor on confidence interval ( higher the value higher the exploration )\n",
    "ctxtVecLen = 100\n",
    "\n",
    "LinUCBPolicy = LinUCB(kArms, alpha, ctxtVecLen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "941"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noOfMatches = 0\n",
    "tCnter = Counter()\n",
    "with open('./dataset.txt') as fp:\n",
    "    for lineNo, eachRecord in enumerate(fp):\n",
    "        data_arm = int(eachRecord.split(' ')[0])\n",
    "        data_reward = float(eachRecord.split()[1])\n",
    "        covariate_string_ltdoist = eachRecord.split()[2:]\n",
    "        data_x_array = np.array([float(eCov) for eCov in eachRecord.split()[2:]])\n",
    "        tCnter[ data_arm ] += data_reward\n",
    "    \n",
    "        if np.random.randint(1,11) == data_arm:\n",
    "            noOfMatches += 1\n",
    "noOfMatches            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinUCB Object with 10 arms and with alpha 0.5\n",
      "Total Estimated Reward:\t 0.2538382804503582 977 248.0\n",
      "Counter({2: 1490, 5: 1023, 1: 996, 4: 994, 7: 960, 10: 950, 9: 923, 8: 908, 3: 883, 6: 873})\n"
     ]
    }
   ],
   "source": [
    "class LinUCB():\n",
    "    '''\n",
    "        This class implements LinUCB Disjoint algorithm\n",
    "    '''\n",
    "    \n",
    "    def __init__( self,  arm_ids, alpha, ctxtVecLen):\n",
    "        \n",
    "        '''\n",
    "            alpha : Controls exploration; \n",
    "                    Higher the alpha, wider the confidence interval and higher the chance of trying any given arm;\n",
    "           \n",
    "            kArms: Number of arms\n",
    "            \n",
    "            ctxtVecLen: length of the feature vector\n",
    "            \n",
    "        '''\n",
    "        \n",
    "        self.kArms      = len(arm_ids)\n",
    "        self.alpha      = alpha\n",
    "        self.ctxtVecLen = ctxtVecLen\n",
    "        \n",
    "        # A: (ctxtVecLen x ctxtVecLen) matrix = D_a.T * D_a + I_d  ( Where a is indexing on arms array)\n",
    "        # The inverse of A is used in ridge regression \n",
    "        self.A_a = {}\n",
    "        for idx, arm_id in enumerate(arm_ids):\n",
    "            self.A_a[arm_id] = np.identity(ctxtVecLen) # A = D_T * D ( Where D is n*p matrix)\n",
    "\n",
    "        # b: (ctxtVecLen x 1) corresponding response vector. \n",
    "        # Equals to D_a.T * c_a in ridge regression formulation\n",
    "        self.b_a = {}\n",
    "        for idx, arm_id in enumerate(arm_ids):\n",
    "            self.b_a[arm_id] = np.zeros([ctxtVecLen,1]) # b = D_T * RV ( where RV is n*1 matrix )\n",
    "        \n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f'LinUCB Object with {kArms} arms and with alpha {alpha}'.format(self.alpha, self.kArms, self.ctxtVecLen) \n",
    "    \n",
    "    def select_arm(self, ctxtVec):\n",
    "        ''' Returns the index of the next arm to pull '''    \n",
    "        \n",
    "        # Reshape covariates input into (d x 1) shape vector\n",
    "        ctxtVec = ctxtVec.reshape([-1,1])\n",
    "\n",
    "        ucb = []\n",
    "        for idx, arm_id in enumerate(np.random.permutation(list(LinUCBPolicy.A_a.keys()) )):\n",
    "            # Find A inverse for ridge regression\n",
    "            A_inv = np.linalg.inv(self.A_a[arm_id])\n",
    "            \n",
    "            # Perform ridge regression to obtain estimate of covariate coefficients theta\n",
    "            # theta is (ctxtVecLen x 1) dimension vector\n",
    "            theta = np.dot(A_inv, self.b_a[arm_id])\n",
    "            \n",
    "            ucb.append( \n",
    "                (\n",
    "                    arm_id,\n",
    "                    (np.dot(theta.T, ctxtVec) + self.alpha * np.sqrt(np.dot(ctxtVec.T, np.dot(A_inv,ctxtVec))))[0][0] \n",
    "                )\n",
    "            )                \n",
    "        return( max(ucb,key=lambda x:x[1])[0] )            \n",
    "    \n",
    "    def update(self, ctxtVec, chosen_arm, reward):\n",
    "        '''        \n",
    "            After we pull an arm, we get a reward signal back from our system. This function update our algorithm's beliefs\n",
    "            about the quality of the arm we just chosen by providing this reward information.\n",
    "        \n",
    "            chosen_arm : The numeric index of the most recently chosen arm\n",
    "            reward     : The reward received from chossing that arm\n",
    "        '''\n",
    "        \n",
    "        # Reshape covariates input into (d x 1) shape vector\n",
    "        ctxtVec = ctxtVec.reshape([-1,1])        \n",
    "    \n",
    "        # Update A which is (d * d) matrix.\n",
    "        self.A_a[chosen_arm] += np.dot(ctxtVec, ctxtVec.T)\n",
    "        \n",
    "        # Update b which is (d x 1) vector\n",
    "        # reward is scalar\n",
    "        self.b_a[chosen_arm] += reward * ctxtVec        \n",
    "        \n",
    "\n",
    "    \n",
    "kArms      = 10\n",
    "alpha      = 0.5  # scalar factor on confidence interval ( higher the value higher the exploration )\n",
    "ctxtVecLen = 100\n",
    "\n",
    "\n",
    "\n",
    "arms_ids = list( range(1, kArms+1))\n",
    "LinUCBPolicy = LinUCB(arms_ids, alpha, ctxtVecLen)        \n",
    "print(LinUCBPolicy)\n",
    "\n",
    "tCtr = Counter()\n",
    "noOfMatches = 0\n",
    "cumulative_reward = 0 \n",
    "\n",
    "totalReward = 0\n",
    "\n",
    "tCnter = Counter()\n",
    "with open('./dataset.txt') as fp:\n",
    "    for idx, eachRecord in enumerate(fp):\n",
    "        data_arm = int(eachRecord.split(' ')[0])\n",
    "        data_reward = float(eachRecord.split()[1])\n",
    "        covariate_string_list = eachRecord.split()[2:]        \n",
    "        data_x_array = np.array([float(eCov) for eCov in eachRecord.split()[2:]])\n",
    "        selected_arm = LinUCBPolicy.select_arm( data_x_array )\n",
    "        \n",
    "        tCnter[selected_arm] += 1\n",
    "        \n",
    "        if selected_arm == data_arm:\n",
    "            noOfMatches += 1\n",
    "            cumulative_reward = cumulative_reward + data_reward\n",
    "            LinUCBPolicy.update(data_x_array, selected_arm, data_reward) \n",
    "            totalReward += data_reward                                \n",
    "noOfMatches, totalReward\n",
    "\n",
    "\n",
    "print('Total Estimated Reward:\\t', totalReward/noOfMatches, noOfMatches, totalReward)\n",
    "\n",
    "\n",
    "print(tCnter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
